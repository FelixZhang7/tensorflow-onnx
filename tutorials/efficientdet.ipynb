{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting efficientdet from Tensorflow to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google recently [published the new object detection model efficientdet](\n",
    "https://github.com/google/automl/tree/master/efficientdet) that show great performance and accuracy. The models are found [here](https://github.com/google/automl/tree/master/efficientdet). \n",
    "This tutorial shows how to convert it to ONNX.\n",
    "\n",
    "To start, we setup a few environment variables, download source and the pre-trained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "%cd /tmp\n",
    "\n",
    "HOME = os.getcwd()\n",
    "MODEL = \"efficientdet-d0\"\n",
    "os.environ['PYTHONPATH'] = os.path.join(HOME, \"tpu\")\n",
    "os.environ['MODEL'] = MODEL\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the code. At the time of this writing the last\n",
    "# commit is 6ecb218626da627ca4c4e4bed4b760c7e66a1b70.\n",
    "%cd {HOME}\n",
    "!git clone https://github.com/google/automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}/automl/efficientdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://storage.googleapis.com/cloud-tpu-checkpoints/efficientdet/coco/$MODEL.tar.gz\n",
    "!tar -C /tmp -zxf $MODEL.tar.gz\n",
    "!wget -O img.png  -q 'https://user-images.githubusercontent.com/11736571/77320690-099af300-6d37-11ea-9d86-24f14dc2d540.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sdb/home/tf/tensorflow/automl/efficientdet\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/sdb/home/tf/tensorflow/automl/efficientdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import inference\n",
    "from inference import *\n",
    "import PIL\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the checkpoint and export the final saved-model. We use existing code but need to make a small change in the code:\n",
    "\n",
    "In automl/efficientdet/anchors.py find the code with:\n",
    "```\n",
    "top_detections_cls = tf.stack([top_detections_cls[:, 0] * image_scale,\n",
    "                               top_detections_cls[:, 1] * image_scale,\n",
    "                               height * image_scale, width * image_scale,\n",
    "                               top_detections_cls[:, 4]], axis=-1)\n",
    "```\n",
    "and change axis from -1 to 1.\n",
    "\n",
    "Then find\n",
    "```\n",
    "if disable_pyfun:\n",
    "  return _generate_detections_tf(\n",
    "      cls_outputs,\n",
    "      box_outputs,\n",
    "      self._anchors.boxes,\n",
    "      indices,\n",
    "      classes,\n",
    "      image_id,\n",
    "      image_scale,\n",
    "      self._num_classes,\n",
    "      min_score_thresh=min_score_thresh,\n",
    "      max_boxes_to_draw=max_boxes_to_draw,\n",
    "      use_native_nms=False\n",
    "  )\n",
    "```\n",
    "and change use_native_nms from False to True.\n",
    "\n",
    "Now run the code below to create the final saved-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driver(ServingDriver):\n",
    "    def __init__(self, model_name, ckpt_path, image_size,\n",
    "                 batch_size=1, num_classes=None, label_id_mapping=None):\n",
    "        super(Driver, self).__init__(model_name, ckpt_path, image_size, batch_size, num_classes, label_id_mapping)\n",
    "        self.disable_pyfun = True\n",
    "\n",
    "    def export(self, output_dir):\n",
    "        \"\"\"Export a saved model.\"\"\"\n",
    "        signitures = self.signitures\n",
    "        signature_def_map = {\n",
    "            'serving_default':\n",
    "                tf.saved_model.predict_signature_def(\n",
    "                    {signitures['image_arrays'].name: signitures['image_arrays']},\n",
    "                    {signitures['prediction'].name: signitures['prediction']}),\n",
    "        }\n",
    "        b = tf.saved_model.Builder(output_dir)\n",
    "        b.add_meta_graph_and_variables(\n",
    "            self.sess,\n",
    "            tags=['serve'],\n",
    "            signature_def_map=signature_def_map,\n",
    "            assets_collection=tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS),\n",
    "            clear_devices=True)\n",
    "        b.save()\n",
    "        logging.info('Model saved at %s', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for f in [\"img.png\"]:\n",
    "    imgs.append(np.array(PIL.Image.open(f)))\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "output = os.path.join('.', MODEL)\n",
    "if tf.io.gfile.exists(output):\n",
    "    tf.io.gfile.rmtree(output)\n",
    "\n",
    "driver = Driver(MODEL, os.path.join('/tmp', MODEL), image_size=512, batch_size=len(imgs))\n",
    "driver.build()\n",
    "driver.export(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert to ONNX directly from the Install and run tf2onnx directly on the saved-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/onnx/tensorflow-onnx\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python -m tf2onnx.convert --opset 11 --saved-model $MODEL --output $MODEL.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O img.png  -q 'https://user-images.githubusercontent.com/11736571/77320690-099af300-6d37-11ea-9d86-24f14dc2d540.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the ONNX model we can write a quick demo using tensorflow and onnxruntime.\n",
    "The model returns an numpy array of shape [batch,detections,7]. detections are limitited to 50.\n",
    "The 7 float32 retuned for each detection are\n",
    "```\n",
    "box = detection[1:5], as ymin, xmin, ymax, xmax\n",
    "                (xmax and ymax are offsets to xmin and ymin)\n",
    "classes = detection[6], the coco label\n",
    "scores = detection[5], the score, values above 0.2 are probably good detections\n",
    "```\n",
    "Some functions to draw the bounding boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"img.png\")\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# we feed a batch of images. Because the model can be any image size and numpy \n",
    "# can't handle such batches we keep the batch size at 1.\n",
    "images = np.array([np.asarray(img, dtype='uint8')])\n",
    "\n",
    "coco_classes = {\n",
    "    1: 'person',\n",
    "    2: 'bicycle',\n",
    "    3: 'car',\n",
    "    4: 'motorcycle',\n",
    "    5: 'airplane',\n",
    "    6: 'bus',\n",
    "    7: 'train',\n",
    "    8: 'truck',\n",
    "    9: 'boat',\n",
    "    10: 'traffic light',\n",
    "}\n",
    "\n",
    "\n",
    "def draw_detection(draw, d, c):\n",
    "    \"\"\"Draw box and label for 1 detection.\"\"\"\n",
    "    ymin, xmin, ymax, xmax = d\n",
    "    xmax += xmin\n",
    "    ymax += ymin\n",
    "    label = coco_classes[c]\n",
    "    # print(ymin, xmin, ymax, xmax, label)\n",
    "    label_size = draw.textsize(label)\n",
    "    if ymax - label_size[1] >= 0:\n",
    "        text_origin = tuple(np.array([xmin, ymax - label_size[1]]))\n",
    "    else:\n",
    "        text_origin = tuple(np.array([xmin, ymax + 1]))\n",
    "    color = ImageColor.getrgb(\"red\")\n",
    "    thickness = 0\n",
    "    draw.rectangle([xmin + thickness, ymax + thickness, xmax - thickness, ymin - thickness], outline=color)\n",
    "    draw.text(text_origin, label, fill=color)\n",
    "    \n",
    "\n",
    "def one_image(img, predictions, min_score=0.2):\n",
    "    img = Image.fromarray(img, mode='RGB')\n",
    "    boxes = predictions[:, 1:5]\n",
    "    classes = predictions[:, 6].astype(int)\n",
    "    scores = predictions[:, 5]\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for idx in range(predictions.shape[0]):\n",
    "        if scores[idx] < min_score:\n",
    "            continue\n",
    "        draw_detection(draw, boxes[idx], classes[idx])\n",
    "    plt.figure(figsize=(80, 40))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the inference on tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    tf.compat.v1.saved_model.load(sess, ['serve'], os.path.join(\".\", MODEL))\n",
    "    detections = sess.run('detections:0', {\"image_arrays:0\": images})\n",
    "    for batch in range(0, detections.shape[0]):\n",
    "        one_image(images[batch], detections[batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally run the inference using onnxruntime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "sess = rt.InferenceSession(MODEL + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4965421438217163 sec per inference\n"
     ]
    }
   ],
   "source": [
    "detections = sess.run(['detections:0'], {\"image_arrays:0\": images})\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    detections = sess.run(['detections:0'], {\"image_arrays:0\": images})\n",
    "print((time.time()-start) / 10, \"sec per inference\")\n",
    "detections = detections[0]\n",
    "for batch in range(0, detections.shape[0]):\n",
    "    one_image(images[batch], detections[batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "563px",
    "left": "1026px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
